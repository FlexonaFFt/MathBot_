import numpy as np

# Заданные данные
X = np.array([[1, 17, 130, 523, 2517], 
            [1, 22,  180, 518, 2801], 
            [1, 18,  217, 510, 2573],  
            [1, 24, 103, 516, 2643], 
            [1, 19, 171, 511, 2801], 
            [1, 20, 180, 471, 2815], 
            [1, 17,  140, 523, 2527], 
            [1, 21, 92, 498, 2735], 
            [1, 18,  173, 542, 2817], 
            [1, 22,  87, 501, 2736], 
            [1, 20,  93, 471, 2682], 
            [1, 17, 210, 523, 2593],
            [1, 15, 110, 538, 2627], 
            [1, 21, 86, 472, 2532],
            [1, 15, 175, 467, 2693]])

y = np.array([401,452,478,397,453,427,396,399,418,413,412,423,393,381,401])

# Определить статистические для β_0^*,β_1^*,β_2^*,β_3^*,β_4^* параметров линейной множественной регрессии
beta = np.linalg.inv(X.T @ X) @ X.T @ y

# Вычислить коэффициент детерминации R^2
y_pred = X @ beta
SSR = np.sum((y_pred - np.mean(y))**2)
SST = np.sum((y - np.mean(y))**2)
R2 = SSR / SST

# Вычислить ошибки
n = len(y)
m = X.shape[1] - 1
errors = y - y_pred
S2_e = np.sum(errors**2) / (n - m - 1)

# Вычислить стандартные ошибки коэффициентов
X_inv = np.linalg.inv(X.T @ X)
S_beta = np.sqrt(np.diag(S2_e * X_inv))

# Оценить эффективность влияния независимых переменных x_i1,x_i2,x_i3 на признак Y с помощью нормированных коэффициентов регрессии
S_y = np.sqrt((y.T @ y) / n - np.mean(y)**2)
a = beta * S_beta / S_y

print(f"β_0^* = {beta[0]}, β_1^* = {beta[1]}, β_2^* = {beta[2]}, β_3^* = {beta[3]}, β_4^* = {beta[4]}")
print(f"R^2 = {R2}")
print(f"a_1 = {a[1]}, a_2 = {a[2]}, a_3 = {a[3]}, a_4 = {a[4]}")